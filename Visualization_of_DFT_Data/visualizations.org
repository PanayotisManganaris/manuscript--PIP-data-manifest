#+TITLE: Visualizing Perovskite Dataset
#+AUTHOR: Panayotis Manganaris
#+EMAIL: pmangana@purdue.edu
#+PROPERTY: header-args :session aikit :kernel mrg :async yes :pandoc org
* dependencies
clone the following repositories into your home "src" directory to use
this notebook with the most recent tools

https://github.com/PanayotisManganaris/cmcl
https://github.com/PanayotisManganaris/yogi
https://github.com/PanayotisManganaris/spyglass

if something does not work due to one of these libraries, be sure to
pull updates both for the above repositories and for this notebook. If
the error persists, contact me.

Alternatively, use the curated tool hosted by nanoHUB at
https://nanohub.org/tools/mrsicmsnotes
#+begin_src jupyter-python :exports results :results raw drawer
  %load_ext autoreload
  %autoreload 2
#+end_src
  
#+begin_src jupyter-python :exports results :results raw drawer
  import sys, os
  sys.path.append(os.path.expanduser("~/src/cmcl"))
  # featurization
  import cmcl
  from cmcl import Categories
#+end_src

#+begin_src jupyter-python :exports results :results raw drawer
  # data tools
  import pandas as pd
  import numpy as np
  # preprocessing
  from sklearn.preprocessing import Normalizer, StandardScaler
  # visualization
  import matplotlib.pyplot as plt
  import seaborn as sns
#+end_src

* load data
#+begin_src jupyter-python :exports results :results raw drawer
  sqlbase = """SELECT *
              FROM mannodi_base"""
  sqlref = """SELECT *
              FROM mannodi_ref_elprop"""
  sqlalmora = """SELECT *
                 FROM almora_agg"""
  with sqlite3.connect("/home/panos/src/cmcl/cmcl/db/perovskites.db") as conn:
      df = pd.read_sql(sqlbase, conn, index_col="index")
      lookup = pd.read_sql(sqlref, conn, index_col='index')
      almora = pd.read_sql(sqlalmora, conn, index_col='index')
#+end_src

#+RESULTS:

* Composition
** Clean Data and Compute Composition Vectors 
#+begin_src jupyter-python :exports results :results raw drawer
  lookup = lookup.set_index("Formula")
  df = df.set_index(["Formula", "sim_cell"], append=True)
#+end_src

*** subset column labels
cmcl provides an "ft" (feature) pandas DataFrame accessor. This
accessor exposes batch feature extraction tools. The function ft.comp
extracts composition vectors from the formula string in a dataframe
(or dataframe index).

- drop formula with large lattice parameter difference between HSE and PBE (calculation to be rerun)
- large structural deformation identified by observing cubicity metric -- well outside of 5-10% spec?
#+begin_src jupyter-python :exports results :results raw drawer
  df = df.drop(index=["Rb0.375Cs0.625GeBr3", "RbGeBr1.125Cl1.875", "K0.75Cs0.25GeI3", "K8Sn8I9Cl15"], level=1)
  maincomp = df.ft.comp().iloc[:, :14:]
  empcomp = df.ft.comp().loc[:, ["FA", "MA", "Cs", "Pb", "Sn", "I", "Br", "Cl"]]
#+end_src

*** auto subset index
The abx function of the collect accessor is a convenience function for
grouping the resulting composition constituents by site membership
#+begin_src jupyter-python :exports results :results raw drawer
  size = df.index.isin(["2x2x2"], level="sim_cell")
  #maincomp
  maincomp = maincomp.collect.abx()
  mcg = maincomp.groupby(level=0, axis=1).sum()
  mvB, mvX, mvA, = mcg.A.isin([1, 8]), mcg.B.isin([1, 8]), mcg.X.isin([3, 24])
  #emcomp
  empcomp = empcomp.collect.abx()
  ecg = empcomp.groupby(level=0, axis=1).sum()
  evB, evX, evA, = ecg.A.isin([1, 8]), ecg.B.isin([1, 8]), ecg.X.isin([3, 24])
  #subset indexes
  mfocus = size*mvB*mvA*mvX
  efocus = size*evB*evA*evX
#+end_src

*** apply subsets
#+begin_src jupyter-python :exports results :results raw drawer
  mc = maincomp[mfocus]
  ec = empcomp[efocus]
  my = df[mfocus]
  ey = df[efocus] #only 56 compounds
#+end_src

*** generate mix categories
this can be used with the logif tool in categories to quickly
categorize records by their mix status. that status is assigned to the
index of the respective tables for further reference

#+begin_src jupyter-python :exports results :results raw drawer
  mixlog = mc.groupby(level=0, axis=1).count()
  mix = mixlog.pipe(Categories.logif, condition=lambda x: x>1, default="pure", catstring="and")
  mc = mc.assign(mix=mix).set_index("mix", append=True)
  my = my.assign(mix=mix).set_index("mix", append=True)
#+end_src

The derive_from function can be used to compute the site-averaged
properties of each record.

It performs a three-way N-to-N table join, performs a weighted
averaging of any resulting redundant entries, and finally reshapes the
results to be consistent with the outermost indices of the accessed
data frame. Hence to obtain the site averaged properties, the
composition table column labels must be grouped first, as above.

#+begin_src jupyter-python :exports results :results raw drawer
  mp = mc.ft.derive_from(lookup, "element", "Formula")
#+end_src

* Target space
The main target of interest in this exercise is the Perovskite band
gap.

A number of properties including band gap and dielectric constant have
been collected from DFT computations using the PBE functional.

These properties are targets for modeling. Ideally, an empirical model
can be found that fits to the underlying quantum mechanics, thereby
acting as a surrogate for the DFT function in an active learning
strategy which can quickly recommend compositions as high-performing
candidates for DFT calculation.

The target space is briefly summarized in both uni-variate and bi-variate views

Note: there are an additional two "SLME" properties in the dataset
(not shown here) that have extremely strong relations with band
gap. They are computed using the band gap and a reference
solar-absorption spectra. cmcl does not yet have a utility for
computing them, so they are included in the sample data for reference.

#+begin_src jupyter-python :exports results :results raw drawer
  plt.style.use('dark_background')
  p = sns.pairplot(my.filter(regex=r"PBE|dielc").drop("PBE_dbg_eV", axis=1).assign(mix=mix), hue='mix')
  p.figure.show()
#+end_src

* Feature space
** Composition Distributions
composition vectors are a set of primary descriptors for the
Perovskites being examined -- most other meaningful features are at
least partially derived from them. Another primary descriptor is the
crystal structure. For now, it is understood that the 496 records
being examined are all cubic perovskites (within a tolerance). They
differ firstly in composition and secondly in alloy character. Alloy
character as a metric is completely encapsulated in the composition
vectors, but nonetheless represents an important consideration in
ensuring the model's generality.

It will be a goal of modeling to create regressions that will be able
to extrapolate targets between the existing alloy character classes.
(AandBandX-site alloys).

Here, uni-variate distributions over finite bounds on composition
ratios are explored with respect to the alloy class.

#+begin_src jupyter-python :exports results :results raw drawer
  nmc = pd.melt(
      pd.DataFrame(
          mc.fillna(0).pipe(Normalizer(norm="l1").fit_transform), #normalizing the data by each vector's manhattan length gives proportional quantities
          columns=mc.columns,
          index=mc.index).assign(mix=mix),
      id_vars="mix").replace(0, np.NaN).dropna() # eliminate the "zeros" (missing values) to focus on the meaningful data
#+end_src

#+begin_src jupyter-python :exports results :results raw drawer
  with sns.plotting_context("poster"):
      p = sns.catplot(x="value", col="element", data=nmc, col_wrap=5, kind="count", hue="mix",
                      col_order=["Ba", "Ge", "Cl", "Br", "I", "Sn", "Pb", "Cs", "FA", "MA", "Sr", "Ca", "Rb", "K"])
      (p.set_xticklabels(rotation=90))
#+end_src
** Site-Averaged Properties Distributions 
#+begin_src jupyter-python :exports results :results raw drawer
  dxr = pd.IndexSlice
  some_axes = mp.loc[:, dxr[:, mp.columns.get_level_values(1)[0:4]]] #change these level value slices to focus on different site axes or remove slicing to see all
  smp = pd.melt(
      pd.DataFrame(
          some_axes.pipe(StandardScaler().fit_transform), #Z transform scales dimensions so they are comparable
          columns=some_axes.columns,
          index=some_axes.index).assign(mix=mix),
      id_vars="mix").replace(0, np.NaN).dropna() # eliminate "zeros" (missing values) to focus on the meaningful data
#+end_src

#+begin_src jupyter-python :exports results :results raw drawer
  with sns.plotting_context("notebook"):
      p = sns.displot(x="value", col=smp.iloc[:,2], row="site", data=smp, kind="hist", hue="mix", multiple='stack')
#+end_src
* Bi-variate relations
it is unlikely that any of the targets is full explained by a single
composition or composition derived axis. But there are probably
relations.

A Pearson correlation map will be produced to check for strong
relations.

Then, if any exist, they will be plotted in detail.

** targets vs composition
#+begin_src jupyter-python :exports results :results raw drawer
  mc_v_targets = pd.concat([my, mc], axis=1).select_dtypes(np.number).fillna(0)
  pearson = pd.DataFrame(np.corrcoef(mc_v_targets, rowvar=False),
                         columns=mc_v_targets.columns,
                         index=mc_v_targets.columns)
  subset = pearson.filter(regex=r"PBE|dielc|SLME", axis=0).filter(regex=r"^(?!PBE|HSE|SLME|dielc|PV_FOM)")
  #first filter picks targets, second selects bases
  p = sns.heatmap(subset, vmax=1.0, vmin=-1.0, cmap="seismic")
  p.set_xticklabels(p.get_xticklabels(), rotation=45, horizontalalignment='right')
  p.figure.show()
#+end_src

** targets vs site-averaged properties
#+begin_src jupyter-python :exports results :results raw drawer
  mp_v_targets = pd.concat([my, mp], axis=1).select_dtypes(np.number).fillna(0)
  pearson = pd.DataFrame(np.corrcoef(mp_v_targets, rowvar=False),
                         columns=mp_v_targets.columns,
                         index=mp_v_targets.columns)
  subset = pearson.filter(regex=r"PBE|dielc|SLME", axis=0).filter(regex=r"^(?!PBE|HSE|SLME|dielc|PV_FOM)")
  #first filter picks targets, second selects bases
  p = sns.heatmap(subset, vmax=1.0, vmin=-1.0, cmap="seismic")
  p.set_xticklabels(p.get_xticklabels(), rotation=45, horizontalalignment='right')
  p.figure.show()
#+end_src

** correlated axes
* Multivariate relations
unsurprisingly no simple explanations exist. to get a better idea of
what structures statistical models might be able to find in the
complete dataset, the structure and effects of many variables at a
time must be inspected.
